# An谩lisis de Deserci贸n de Clientes Bancarios - VERSIN MEJORADA

## Objetivo

Analizar qu茅 factores influyen en que los clientes abandonen un banco y crear modelos para predecir la deserci贸n, **con manejo apropiado del desbalance del dataset**.

---

## 锔 PROBLEMA IDENTIFICADO: Dataset Desbalanceado

### **An谩lisis del Balance**

- **Deserci贸n**: 2,037 clientes (20.4%)
- **No Deserci贸n**: 7,963 clientes (79.6%)
- **Ratio de balance**: 0.256 (25.6%)
- **Clasificaci贸n**: Dataset DESBALANCEADO

### **Impacto del Desbalance**

- Los modelos originales estaban sesgados hacia la clase mayoritaria
- Baja sensibilidad (recall) en identificar desertores
- M茅tricas enga帽osas (accuracy alta pero recall bajo)

---

## 1.  Variables m谩s importantes para identificar clientes que desertan

### **Metodolog铆a Utilizada**

Para encontrar las variables m谩s importantes, utilizamos tres m茅todos diferentes y los combinamos:

1. **An谩lisis Estad铆stico (F-Score)**: Mide qu茅 tan bien cada variable separa a los clientes que se van de los que se quedan
2. **Informaci贸n Mutua**: Eval煤a qu茅 tan 煤til es cada variable para predecir la deserci贸n
3. **Bosque Aleatorio**: Usa un modelo de 谩rboles para determinar la importancia de cada variable

### **Top 5 Variables M谩s Importantes**

| Posici贸n | Variable        | Puntuaci贸n | Explicaci贸n                                                                                             |
| -------- | --------------- | ---------- | ------------------------------------------------------------------------------------------------------- |
| **1**    | **CreditScore** | 1.00       | El puntaje crediticio es la variable m谩s importante. Los clientes con mejor cr茅dito tienden a quedarse. |
| **2**    | **Geography**   | 0.60       | La ubicaci贸n geogr谩fica del cliente influye significativamente en la deserci贸n.                         |
| **3**    | **Gender**      | 0.34       | El g茅nero del cliente tiene un impacto moderado en la decisi贸n de abandonar.                            |
| **4**    | **Age**         | 0.31       | La edad del cliente es un factor importante para predecir la deserci贸n.                                 |
| **5**    | **Tenure**      | 0.24       | El tiempo que el cliente lleva en el banco es relevante para predecir si se ir谩.                        |

---

## 2. Modelos creados para predecir la deserci贸n

### **Modelos Originales (Sin manejo de desbalance)**

- **Bosque Aleatorio (Random Forest)**: Modelo de aprendizaje autom谩tico que usa m煤ltiples 谩rboles de decisi贸n
- **Regresi贸n Log铆stica**: Modelo estad铆stico lineal para clasificaci贸n

### **Modelos Mejorados (Con manejo de desbalance)**

- **Bosque Aleatorio con Class Weights**: Asigna mayor peso a la clase minoritaria
- **Regresi贸n Log铆stica con Class Weights**: Compensa el desbalance con pesos ajustados

### **T茅cnica de Balanceo Aplicada**

- **Class Weights**: Asignar mayor peso a la clase minoritaria (deserci贸n)
- **Peso para No Deserci贸n**: 0.63
- **Peso para Deserci贸n**: 2.45
- **Objetivo**: Compensar el desbalance del dataset (20.4% vs 79.6%)

---

## 3. Resultados de los modelos mejorados

### **M茅tricas de Rendimiento - Modelos Mejorados**

| Modelo                            | Accuracy | Precision | Recall    | F1-Score  | AUC-ROC |
| --------------------------------- | -------- | --------- | --------- | --------- | ------- |
| **Random Forest (Class Weights)** | 78.5%    | 45.7%     | 31.7%     | 37.4%     | 70.2%   |
| **Log铆stico (Class Weights)**     | 70.5%    | 37.3%     | **65.8%** | **47.6%** | 74.8%   |

### **Comparaci贸n con Modelos Originales**

| Modelo            | F1-Score Original | F1-Score Mejorado | Mejora    |
| ----------------- | ----------------- | ----------------- | --------- |
| **Random Forest** | 38.0%             | 37.4%             | Similar   |
| **Log铆stico**     | 11.7%             | **47.6%**         | **+308%** |

---

## 4. Mejor modelo identificado

### **Log铆stico con Class Weights**

**Razones de la elecci贸n:**

- **F1-Score m谩s alto**: 47.6% (vs 37.4% del Random Forest)
- **Recall excepcional**: 65.8% (identifica al 66% de los desertores reales)
- **Mejora dram谩tica**: +308% en F1-Score vs modelo original
- **Balance adecuado**: Entre precisi贸n y sensibilidad

### **Interpretaci贸n del rendimiento**

- **Recall de 65.8%**: De cada 100 clientes que realmente desertan, el modelo identifica correctamente a 66
- **F1-Score de 47.6%**: Balance saludable entre precisi贸n y sensibilidad
- **AUC-ROC de 74.8%**: Buena capacidad discriminativa

---

## 5. Impacto de las mejoras

### **Mejoras Obtenidas**

1. **Recall del Log铆stico**: De 6.9% a 65.8% (+857%)
2. **F1-Score del Log铆stico**: De 11.7% a 47.6% (+308%)
3. **Identificaci贸n de desertores**: 10 veces m谩s efectivo

### **Impacto en el Negocio**

- **Mejor identificaci贸n**: Ahora se identifican al 66% de los clientes en riesgo
- **Estrategias de retenci贸n**: M谩s efectivas al tener mejor informaci贸n
- **Reducci贸n de p茅rdidas**: Mayor capacidad de prevenir deserciones

---

## 6. T茅cnicas aplicadas para el balanceo

### **Class Weights**

- **Concepto**: Asignar mayor peso a la clase minoritaria durante el entrenamiento
- **Implementaci贸n**: Autom谩tica en scikit-learn con `class_weight='balanced'`
- **Ventajas**: Simple, efectivo, no requiere modificar los datos

### **Alternativas Consideradas**

- **SMOTE**: Generaci贸n de datos sint茅ticos (no implementado en esta versi贸n)
- **Undersampling**: Reducci贸n de la clase mayoritaria
- **Ensemble Methods**: Combinaci贸n de m煤ltiples modelos

---

## 7. Comparaci贸n final de modelos

### **Ranking por F1-Score (Mejorado)**

1. **Log铆stico (Class Weights)**: 47.6%
2. **Random Forest (Class Weights)**: 37.4%

### **Ranking por Recall (Mejorado)**

1. **Log铆stico (Class Weights)**: 65.8%
2. **Random Forest (Class Weights)**: 31.7%

### **Ranking por AUC-ROC (Mejorado)**

1. **Log铆stico (Class Weights)**: 74.8%
2. **Random Forest (Class Weights)**: 70.2%

---

## Conclusiones Principales

1. **El desbalance era cr铆tico**: Los modelos originales no pod铆an identificar desertores efectivamente
2. **Class Weights es efectivo**: Mejor贸 dram谩ticamente el rendimiento del modelo log铆stico
3. **El Log铆stico es superior**: Con balanceo, supera al Random Forest en todas las m茅tricas importantes
4. **Recall mejorado significativamente**: De 6.9% a 65.8% (+857%)
5. **Aplicaci贸n pr谩ctica viable**: El modelo puede identificar efectivamente clientes en riesgo

---

## Archivos Generados

### **An谩lisis Original**

- `importancia_variables.csv`: Ranking de variables importantes
- `resultados_comparacion.csv`: Comparaci贸n de rendimiento de modelos originales
- `README.md`: Documentaci贸n original

### **An谩lisis Mejorado**

- `resultados_mejorados.csv`: Resultados con manejo de desbalance
- `modelos_balanceados_simple.py`: Script de modelos mejorados
- `resumen_mejoras_balanceo.py`: Resumen de mejoras obtenidas
- `README_MEJORADO.md`: Esta documentaci贸n

### **Visualizaciones**

- `matriz_correlacion.png`: Correlaciones entre variables
- `curvas_roc.png`: Curvas ROC de modelos originales
- `curvas_roc_mejoradas.png`: Curvas ROC de modelos mejorados
- `curvas_precision_recall.png`: Curvas Precision-Recall

---

## Recomendaciones para Implementaci贸n

### **Modelo Recomendado**

- **Usar**: Log铆stico con Class Weights
- **M茅tricas a monitorear**: F1-Score y Recall
- **Threshold**: Considerar ajustar seg煤n necesidades del negocio


---

## Resumen de Mejoras

| Aspecto                          | Antes    | Despu茅s   | Mejora        |
| -------------------------------- | -------- | --------- | ------------- |
| **Recall del Log铆stico**         | 6.9%     | 65.8%     | +857%         |
| **F1-Score del Log铆stico**       | 11.7%    | 47.6%     | +308%         |
| **Identificaci贸n de Desertores** | Muy baja | Alta      | Dram谩tica     |
| **Aplicabilidad Pr谩ctica**       | Limitada | Excelente | Significativa |

**El manejo del desbalance transform贸 completamente la utilidad pr谩ctica del modelo para identificar clientes en riesgo de deserci贸n.**
