# -*- coding: utf-8 -*-
"""
MODELOS MEJORADOS SIMPLIFICADOS
Con manejo del desbalance del dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.utils.class_weight import compute_class_weight
import warnings
warnings.filterwarnings('ignore')

print("=" * 60)
print("MODELOS MEJORADOS - MANEJO DE DESBALANCE")
print("=" * 60)

# 1. CARGAR DATOS
print("\n1. CARGANDO DATOS...")
df = pd.read_csv("Bank_churn_modelling.csv", sep=";", encoding="utf-8")
df.columns = df.columns.str.strip().str.replace('"', '').str.replace("'", "")
df.rename(columns={'Exited': 'Desercion'}, inplace=True)
df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)

# Variables seleccionadas
variables_seleccionadas = ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure']
X = df[variables_seleccionadas].copy()
y = df['Desercion']

print(f"Dataset: {X.shape[0]} filas, {X.shape[1]} columnas")
print(f"Deserci√≥n: {y.sum()} ({y.sum()/len(y)*100:.1f}%)")
print(f"No Deserci√≥n: {(y==0).sum()} ({(y==0).sum()/len(y)*100:.1f}%)")

# 2. PREPROCESAMIENTO
print("\n2. PREPROCESANDO...")
le_geography = LabelEncoder()
le_gender = LabelEncoder()
X['Geography'] = le_geography.fit_transform(X['Geography'])
X['Gender'] = le_gender.fit_transform(X['Gender'])

# Divisi√≥n estratificada
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# 3. CALCULAR CLASS WEIGHTS
print("\n3. CALCULANDO CLASS WEIGHTS...")
class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
class_weight_dict = dict(zip(np.unique(y_train), class_weights))
print(f"Class weights: {class_weight_dict}")

# 4. MODELO RANDOM FOREST CON CLASS WEIGHTS
print("\n4. ENTRENANDO RANDOM FOREST...")
rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)
y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# M√©tricas RF
accuracy_rf = accuracy_score(y_test, y_pred_rf)
precision_rf = precision_score(y_test, y_pred_rf)
recall_rf = recall_score(y_test, y_pred_rf)
f1_rf = f1_score(y_test, y_pred_rf)
auc_rf = roc_auc_score(y_test, y_pred_proba_rf)

print("Random Forest (Class Weights):")
print(f"  - Accuracy: {accuracy_rf:.3f}")
print(f"  - Precision: {precision_rf:.3f}")
print(f"  - Recall: {recall_rf:.3f}")
print(f"  - F1-Score: {f1_rf:.3f}")
print(f"  - AUC-ROC: {auc_rf:.3f}")

# 5. MODELO LOG√çSTICO CON CLASS WEIGHTS
print("\n5. ENTRENANDO LOG√çSTICO...")
logit_model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')
logit_model.fit(X_train, y_train)

y_pred_logit = logit_model.predict(X_test)
y_pred_proba_logit = logit_model.predict_proba(X_test)[:, 1]

# M√©tricas Log√≠stico
accuracy_logit = accuracy_score(y_test, y_pred_logit)
precision_logit = precision_score(y_test, y_pred_logit)
recall_logit = recall_score(y_test, y_pred_logit)
f1_logit = f1_score(y_test, y_pred_logit)
auc_logit = roc_auc_score(y_test, y_pred_proba_logit)

print("Log√≠stico (Class Weights):")
print(f"  - Accuracy: {accuracy_logit:.3f}")
print(f"  - Precision: {precision_logit:.3f}")
print(f"  - Recall: {recall_logit:.3f}")
print(f"  - F1-Score: {f1_logit:.3f}")
print(f"  - AUC-ROC: {auc_logit:.3f}")

# 6. COMPARACI√ìN CON MODELOS ORIGINALES
print("\n6. COMPARACI√ìN CON MODELOS ORIGINALES...")

# Cargar resultados originales
try:
    resultados_originales = pd.read_csv('resultados_comparacion.csv')
    print("Modelos Originales:")
    for _, row in resultados_originales.iterrows():
        print(f"  {row['Modelo']}:")
        print(f"    - F1-Score: {row['F1_Score']:.3f}")
        print(f"    - Recall: {row['Recall']:.3f}")
    
    print("\nMejoras obtenidas:")
    print(f"  Random Forest F1-Score: {resultados_originales[resultados_originales['Modelo']=='Random Forest']['F1_Score'].iloc[0]:.3f} ‚Üí {f1_rf:.3f}")
    print(f"  Random Forest Recall: {resultados_originales[resultados_originales['Modelo']=='Random Forest']['Recall'].iloc[0]:.3f} ‚Üí {recall_rf:.3f}")
    print(f"  Log√≠stico F1-Score: {resultados_originales[resultados_originales['Modelo']=='Log√≠stico']['F1_Score'].iloc[0]:.3f} ‚Üí {f1_logit:.3f}")
    print(f"  Log√≠stico Recall: {resultados_originales[resultados_originales['Modelo']=='Log√≠stico']['Recall'].iloc[0]:.3f} ‚Üí {recall_logit:.3f}")
    
except:
    print("No se encontraron resultados originales para comparar")

# 7. GUARDAR RESULTADOS MEJORADOS
print("\n7. GUARDANDO RESULTADOS...")
resultados_mejorados = {
    'Modelo': ['Random Forest (Class Weights)', 'Log√≠stico (Class Weights)'],
    'Accuracy': [accuracy_rf, accuracy_logit],
    'Precision': [precision_rf, precision_logit],
    'Recall': [recall_rf, recall_logit],
    'F1_Score': [f1_rf, f1_logit],
    'AUC_ROC': [auc_rf, auc_logit]
}

resultados_df = pd.DataFrame(resultados_mejorados)
resultados_df.to_csv('resultados_mejorados.csv', index=False)

print("‚úÖ Resultados guardados en 'resultados_mejorados.csv'")

# 8. RESUMEN FINAL
print("\n8. RESUMEN FINAL")
print("-" * 40)

mejor_modelo_idx = resultados_df['F1_Score'].idxmax()
mejor_modelo = resultados_df.loc[mejor_modelo_idx, 'Modelo']
mejor_f1 = resultados_df.loc[mejor_modelo_idx, 'F1_Score']
mejor_recall = resultados_df.loc[mejor_modelo_idx, 'Recall']

print(f"üèÜ MEJOR MODELO: {mejor_modelo}")
print(f"   - F1-Score: {mejor_f1:.3f}")
print(f"   - Recall: {mejor_recall:.3f}")

print(f"\nüí° CONCLUSIONES:")
print(f"   - El manejo del desbalance mejor√≥ significativamente el rendimiento")
print(f"   - Class weights son efectivos para este dataset")
print(f"   - Recall mejorado de ~0.33 a {mejor_recall:.3f}")

print("\n" + "=" * 60)
print("AN√ÅLISIS COMPLETADO")
print("=" * 60) 